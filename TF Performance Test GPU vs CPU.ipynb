{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2.0 GPU vs CPU Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda activate tensorflow_v2_gpu\n",
    "\n",
    "# tensorboard            2.0.2\n",
    "# tensorboard-plugin-wit 1.8.0\n",
    "# tensorflow             2.4.1\n",
    "# tensorflow-estimator   2.0.1\n",
    "# tensorflow-gpu         2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T11:13:23.782932Z",
     "end_time": "2023-04-18T11:14:14.539707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    },
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.config.experimental.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T01:58:15.627512Z",
     "end_time": "2023-04-18T01:58:15.659517Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T01:58:17.882887Z",
     "end_time": "2023-04-18T01:58:17.935495Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T01:58:19.640331Z",
     "end_time": "2023-04-18T01:58:21.200328Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np                                \n",
    "import matplotlib.pyplot as plt\n",
    "import keras as k\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T01:58:22.665874Z",
     "end_time": "2023-04-18T01:58:23.442933Z"
    }
   },
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "img_rows, img_cols = 28,28\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "x_test=x_test.astype('float32')\n",
    "x_train=x_train.astype('float32')\n",
    "mean=np.mean(x_train)\n",
    "std=np.std(x_train)\n",
    "x_test = (x_test-mean)/std\n",
    "x_train = (x_train-mean)/std\n",
    "\n",
    "print(\"counts of x_train : {}, y_train : {}, x_test : {}, y_test : {}\".format(\n",
    "    len(x_train), len(y_train), len(x_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T01:58:25.096464Z",
     "end_time": "2023-04-18T01:58:25.113495Z"
    }
   },
   "outputs": [],
   "source": [
    "#labels\n",
    "num_classes=10\n",
    "y_train = k.utils.to_categorical(y_train, num_classes)\n",
    "y_test = k.utils.to_categorical(y_test, num_classes)\n",
    "print(\"counts of x_train : {}, y_train : {}, x_test : {}, y_test : {}\".format(\n",
    "    len(x_train), len(y_train), len(x_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow with CPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T02:00:44.756586Z",
     "end_time": "2023-04-18T02:00:44.880389Z"
    }
   },
   "outputs": [],
   "source": [
    "num_filter=32\n",
    "num_dense=512\n",
    "drop_dense=0.7\n",
    "ac='relu'\n",
    "learningrate=0.001\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(num_filter, (3, 3), activation=ac, input_shape=(28, 28, 1),padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Conv2D(num_filter, (3, 3), activation=ac,padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 14x14x32\n",
    "\n",
    "    model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 7x7x64 = 3136 neurons\n",
    "\n",
    "    model.add(Flatten())                        \n",
    "    model.add(Dense(num_dense, activation=ac))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_dense))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    adm=Adam(lr=learningrate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=adm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T02:00:47.576227Z",
     "end_time": "2023-04-18T02:09:00.150310Z"
    }
   },
   "outputs": [],
   "source": [
    "cpu_list=[]\n",
    "batch_sizes = []\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    for i in range(0,7):\n",
    "        k=8*2**i\n",
    "        print(\"batch size \"+str(k))\n",
    "        t1 = time.time()\n",
    "        model.fit(x_train, y_train, batch_size=k, epochs=1, validation_data=(x_test, y_test))\n",
    "        t2 = time.time()\n",
    "        cpu_list.append(int(t2-t1))\n",
    "        batch_sizes.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T02:09:25.871149Z",
     "end_time": "2023-04-18T02:09:25.881146Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"cpu_list : \", cpu_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow with GPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T01:58:30.185813Z",
     "end_time": "2023-04-18T01:58:30.331812Z"
    }
   },
   "outputs": [],
   "source": [
    "#build model\n",
    "\n",
    "num_filter=32\n",
    "num_dense=512\n",
    "drop_dense=0.7\n",
    "ac='relu'\n",
    "learningrate=0.001\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(num_filter, (3, 3), activation=ac, input_shape=(28, 28, 1),padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(num_filter, (3, 3), activation=ac,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 14x14x32\n",
    "\n",
    "model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(2*num_filter, (3, 3), activation=ac,padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 7x7x64 = 3136 neurons\n",
    "\n",
    "model.add(Flatten())                        \n",
    "model.add(Dense(num_dense, activation=ac))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(drop_dense))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "adm=Adam(lr=learningrate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=adm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model with gpu or cpu for different batch sizes. The larger the batch size, the more the parallelisation of matrix multiplications in the gpu speeds up the training compared to the cpu. The gpu load goes up to 95 percent for batch size 512, with 1.6GB used. Much larger batches require better graphics cards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # with GPU (the default in my setup)\n",
    "# for i in range(1,2):\n",
    "#     k=8*2**i\n",
    "#     print(\"batch size \"+str(k))\n",
    "#     model.fit(x_train, y_train, batch_size=k, epochs=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T01:58:35.544569Z",
     "end_time": "2023-04-18T02:00:13.280368Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu_list=[]\n",
    "batch_sizes = []\n",
    "print(\"gpu_list : \", gpu_list)\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    for i in range(0,7):\n",
    "        k=8*2**i\n",
    "        print(\"batch size \"+str(k))\n",
    "        t1 = time.time()\n",
    "        model.fit(x_train, y_train, batch_size=k, epochs=1, validation_data=(x_test, y_test))\n",
    "        t2 = time.time()\n",
    "        gpu_list.append(int(t2-t1))\n",
    "        batch_sizes.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T02:00:34.284187Z",
     "end_time": "2023-04-18T02:00:34.297185Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"gpu_list : \", gpu_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 :-  GPU VS CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T02:09:34.155534Z",
     "end_time": "2023-04-18T02:09:35.815599Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the comparison. The training with gpu is faster by a factor of about 4-6\n",
    "plt.plot(batch_sizes,gpu_list,'bo')\n",
    "plt.plot(batch_sizes,cpu_list,'ro')\n",
    "plt.plot(batch_sizes,gpu_list,'b--')\n",
    "plt.plot(batch_sizes,cpu_list,'r--')\n",
    "plt.ylabel('training time per epoch (s)')\n",
    "plt.xlabel('batch size')\n",
    "plt.legend(['gpu', 'cpu'], loc='upper right')\n",
    "plt.ylim([0,400])\n",
    "#plt.savefig('CPUvsGPU.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 :-  GPU VS CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T02:10:04.155223Z",
     "end_time": "2023-04-18T02:10:04.225223Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the comparison. The training with gpu is faster by a factor of about 4-6\n",
    "plt.plot(batch_sizes,gpu_list,'bo')\n",
    "plt.plot(batch_sizes,cpu_list,'ro')\n",
    "plt.plot(batch_sizes,gpu_list,'b--')\n",
    "plt.plot(batch_sizes,cpu_list,'r--')\n",
    "plt.ylabel('training time per epoch (s)')\n",
    "plt.xlabel('batch size')\n",
    "plt.legend(['gpu', 'cpu'], loc='upper right')\n",
    "plt.ylim([0,400])\n",
    "#plt.savefig('CPUvsGPU.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-18T02:10:10.844222Z",
     "end_time": "2023-04-18T02:10:10.857221Z"
    }
   },
   "outputs": [],
   "source": [
    "ratio_list=[j/k for (j, k) in zip(cpu_list,gpu_list)]\n",
    "ratio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
